{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b80c56-5fe8-4f6e-b14b-1e6bd087f2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from typing import Union\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d4402d-8037-45a2-9a27-be9201faf1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 265\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "DEVICE = (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "torch.set_default_dtype(torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaa6a27-6770-4325-a525-67f90bd00191",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input_layer = nn.Linear(32 * 32 * 3, 512)\n",
    "        self.h1 = nn.Linear(512, 128)\n",
    "        self.h2 = nn.Linear(128, 32)\n",
    "        self.output_layer = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.flatten(x, 1)\n",
    "        out = F.relu(self.input_layer(out))\n",
    "        out = F.relu(self.h1(out))\n",
    "        out = F.relu(self.h2(out))\n",
    "        out = self.output_layer(out)\n",
    "        return out\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return \"MyMLP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6b085b-5d2c-42d3-a0a6-7ecc6d7bc852",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_CIFAR2(train_val_split: float=.9, data_path: str='../data', preprocessor: transforms.Compose=None):\n",
    "    data_train_val = datasets.CIFAR10(\n",
    "        data_path,\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=preprocessor)\n",
    "    \n",
    "    data_test = datasets.CIFAR10(\n",
    "        data_path,\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=preprocessor)\n",
    "\n",
    "    n_train = int(len(data_train_val)*train_val_split)\n",
    "    n_val = len(data_train_val) - n_train\n",
    "\n",
    "    data_train, data_val = random_split(\n",
    "        data_train_val,\n",
    "        [n_train, n_val],\n",
    "        generator=torch.Generator()\n",
    "    )\n",
    "    \n",
    "    label_map = {0: 0, 2: 1}\n",
    "    class_names = ['airplane', 'bird']\n",
    "    \n",
    "    data_train = [(img, label_map[label]) for img, label in data_train if label in [0, 2]]\n",
    "    data_val = [(img, label_map[label]) for img, label in data_val if label in [0, 2]]\n",
    "    data_test = [(img, label_map[label]) for img, label in data_test if label in [0, 2]]\n",
    "\n",
    "    print(\"Size of training set: \", len(data_train))\n",
    "    print(\"Size of validation set: \", len(data_val))\n",
    "    print(\"Size of test set: \", len(data_test))\n",
    "\n",
    "    return (data_train, data_val, data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c9f018-3302-46b3-93b0-c16235ac30fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images(data_set, save=False):\n",
    "    \"\"\"\n",
    "    Display images of planes and birds.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(nrows=8, ncols=2, constrained_layout=True, figsize=(4,10))\n",
    "    fig.suptitle(\"Planes(0) and Birds(1)\")\n",
    "    imgs= (img for img, _ in data_set)\n",
    "    labels= (label for _, label in data_set)\n",
    "\n",
    "    for i, row in enumerate(axes):\n",
    "        for j, ax in enumerate(row):\n",
    "            img, label = next(imgs), next(labels)\n",
    "            while label != j:\n",
    "                img, label = next(imgs), next(labels)\n",
    "            ax.imshow(img, interpolation=\"nearest\", aspect=\"auto\")\n",
    "            ax.axis('off')\n",
    "\n",
    "    if save:\n",
    "        plt.savefig(\"imgs/train_images.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904bfafe-5ffd-4795-bba2-52be61c4c679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_epochs: int, optimizer: optim.Optimizer, model: nn.Module, loss_fn, train_loader: DataLoader, val_loader: DataLoader):\n",
    "    \"\"\"\n",
    "    Train a model with pytorch optimizer.\n",
    "    \"\"\"\n",
    "    print(f\"Training {model} with optimizer\")\n",
    "    n_batch = len(train_loader)\n",
    "    losses_train = []\n",
    "    losses_val = []\n",
    "\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        model.train()\n",
    "        loss_train = 0.0\n",
    "            \n",
    "        for imgs, labels in train_loader:\n",
    "            imgs = imgs.to(device=DEVICE, dtype=torch.double)\n",
    "            labels = labels.to(device=DEVICE)\n",
    "\n",
    "            outputs = model(imgs)\n",
    "\n",
    "            loss = loss_fn(outputs,labels)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss_train += loss.item()\n",
    "\n",
    "        losses_train.append(loss_train / n_batch)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            loss_val = 0.0\n",
    "            for imgs, labels in val_loader:\n",
    "                imgs = imgs.to(device=DEVICE, dtype=torch.double)\n",
    "                labels = labels.to(device=DEVICE)\n",
    "                outputs = model(imgs)\n",
    "                loss = loss_fn(outputs, labels)\n",
    "\n",
    "                loss_val += loss.item()\n",
    "            losses_val.append(loss_val / n_batch)\n",
    "                \n",
    "\n",
    "        if epoch == 1 or epoch % 5 == 0:\n",
    "            print(f\"{datetime.now().time()}, {epoch}, train_loss: {loss_train/n_batch:.5f}, val_loss: {loss_val/n_batch:.5f}\")\n",
    "\n",
    "    return losses_train, losses_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a1a24c-5529-4fea-945c-2b169d922f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_manual_update(n_epochs: int, lr: float, model: nn.Module, loss_fn, train_loader: DataLoader, val_loader: DataLoader, weight_decay: float=0.0, momentum: float=0.0):\n",
    "    \"\"\"\n",
    "    Train a model with manual update to parameters.\n",
    "    \"\"\"\n",
    "    print(f\"Training {model} with manual update\")\n",
    "    n_batch = len(train_loader)\n",
    "    losses_train = []\n",
    "    losses_val = []\n",
    "\n",
    "    # Momentum buffer\n",
    "    m_b = [torch.zeros_like(p) for p in model.parameters()] \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        model.train()\n",
    "        loss_train = 0.0\n",
    "\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs = imgs.to(device=DEVICE, dtype=torch.double)\n",
    "            labels = labels.to(device=DEVICE)\n",
    "\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs,labels)\n",
    "            loss.backward()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for i, p in enumerate(model.parameters()):\n",
    "                    # L2 regularization\n",
    "                    if weight_decay != 0:\n",
    "                        p.grad = p.grad + weight_decay*p.data\n",
    "                    # Momentum\n",
    "                    if momentum != 0:\n",
    "                        m_b[i] = (momentum*m_b[i]) + p.grad\n",
    "                        p.grad = m_b[i]\n",
    "                        \n",
    "                    # Gradient step\n",
    "                    new_params = p.data-lr*p.grad\n",
    "                    p.copy_(new_params)\n",
    "                \n",
    "                        \n",
    "                model.zero_grad()\n",
    "\n",
    "            loss_train += loss.item()\n",
    "\n",
    "        losses_train.append(loss_train / n_batch)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            loss_val = 0.0\n",
    "            for imgs, labels in val_loader:\n",
    "                imgs = imgs.to(device=DEVICE, dtype=torch.double)\n",
    "                labels = labels.to(device=DEVICE)\n",
    "                outputs = model(imgs)\n",
    "                loss = loss_fn(outputs, labels)\n",
    "\n",
    "                loss_val += loss.item()\n",
    "            losses_val.append(loss_val / n_batch)\n",
    "                \n",
    "\n",
    "        if epoch == 1 or epoch % 5 == 0:\n",
    "            print(f\"{datetime.now().time()}, {epoch}, train_loss: {loss_train/n_batch:.5f}, val_loss: {loss_val/n_batch:.5f}\")\n",
    "\n",
    "    return losses_train, losses_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706669f3-682a-4eed-bbda-8ebab767bbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model: torch.nn, loader: DataLoader, calc_confusion_matrix: bool=False):\n",
    "    model.eval()\n",
    "    correct, total, cm, y_pred, y_true = 0, 0, None, list(), list()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Load images and true labels from each batch\n",
    "        for imgs, labels in loader:\n",
    "            imgs = imgs.to(device=DEVICE)\n",
    "            labels = labels.to(device=DEVICE)\n",
    "\n",
    "            # Run predictions. Predicted label = prediction with highest confidence\n",
    "            outputs = model(imgs)\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "        \n",
    "            # Keep track of total and number of correct predictions\n",
    "            total += labels.shape[0]\n",
    "            correct += int((predicted == labels).sum())\n",
    "\n",
    "    # Calculate accuracy\n",
    "    acc = correct / total\n",
    "\n",
    "    if calc_confusion_matrix: \n",
    "        # Calculate confusion matrix with Sklearn\n",
    "        # positive = Airplane = 1, negative = Bird = 0\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        return acc, cm\n",
    "    else: \n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53e784a-832e-44e4-90fe-b4b14b708a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_training_functions(train_loader: DataLoader, val_loader: DataLoader):\n",
    "    \"\"\"\n",
    "    Used to compare the losses and accuracies of the different gradient descent implementations\n",
    "    \"\"\"\n",
    "    batch_size = 256\n",
    "    n_epochs = 5\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    seed = SEED\n",
    "    hparam = {\"lr\": 0.01, \"weight_decay\": 0.01, \"momentum\": 0.9}\n",
    "    \n",
    "    print(\"\\tParameters:\")\n",
    "    print(f\"Batch size: {batch_size}\")\n",
    "    print(f\"Epochs: {n_epochs}\")\n",
    "    print(f\"Loss function: {loss_fn}\")\n",
    "    print(f\"Seed: {seed}\")\n",
    "    [print(f\"{param}: {value}\") for param, value in hparam.items()]\n",
    "    print(\"\\n\", \"=\"*50)\n",
    "    \n",
    "    print(\"\\n\", \"-\"*6, \"Using Pytorch SGD\", \"-\"*6)\n",
    "    torch.manual_seed(SEED)\n",
    "    model_auto = MyMLP()\n",
    "    model_auto.to(device=DEVICE)\n",
    "    optimizer = optim.SGD(model_auto.parameters(), **hparam)\n",
    "\n",
    "    train_loss_auto, val_loss_auto = train(n_epochs, optimizer, model_auto, loss_fn, train_loader, val_loader)\n",
    "    train_acc_auto = evaluate(model_auto, train_loader)\n",
    "    val_acc_auto = evaluate(model_auto, val_loader)\n",
    "    \n",
    "    print(\"\\n\", \"-\"*3, \"Accuracies\", \"-\"*3)\n",
    "    print(f\"Training accuracy: {round(train_acc_auto, 2)}\")\n",
    "    print(f\"Validation accuracy: {round(val_acc_auto, 2)}\")\n",
    "    \n",
    "    print(\"\\n\", \"-\"*6, \"Using manual update\", \"-\"*6)\n",
    "    torch.manual_seed(SEED)\n",
    "    model_manual = MyMLP()\n",
    "    model_manual.to(device=DEVICE)\n",
    "    train_loss_manual, val_loss_manual = train_manual_update(n_epochs, model=model_manual, train_loader=train_loader, val_loader=val_loader, loss_fn=loss_fn, **hparam)\n",
    "    train_acc_manual = evaluate(model_manual, train_loader)\n",
    "    val_acc_manual = evaluate(model_manual, val_loader)\n",
    "    \n",
    "    print(\"\\n\", \"-\"*3, \"Accuracies\", \"-\"*3)\n",
    "    print(f\"Training accuracy: {round(train_acc_manual, 2)}\")\n",
    "    print(f\"Validation accuracy: {round(val_acc_manual, 2)}\")\n",
    "\n",
    "    print(\"\\n\", \"-\"*6, \"Test for equal result\", \"-\"*6)\n",
    "    print(f\"Training loss is equal: {train_loss_auto[-1]:.5f}={train_loss_manual[-1]:.5f}\")\n",
    "    print(f\"Validation loss is equal: {val_loss_auto[-1]:.5f}={val_loss_manual[-1]:.5f}\")\n",
    "    print(f\"Training accuracy is equal: {train_acc_auto:.5f}={train_acc_manual:.5f}\")\n",
    "    print(f\"Validation accuracy is equal: {val_acc_auto:.5f}={val_acc_manual:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73212d55-86a4-4201-815f-216ec049012c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_instances(n_epochs: int, batch_size: int, train_loader: DataLoader, val_loader: DataLoader):\n",
    "    \"\"\"\n",
    "    Train on different hyperparameters using Pytorch SGD\n",
    "    \"\"\"\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    seed = SEED\n",
    "\n",
    "    print(\"\\tGlobal parameters:\")\n",
    "    print(f\"Batch size: {batch_size}\")\n",
    "    print(f\"Epochs: {n_epochs}\")\n",
    "    print(f\"Loss function: {loss_fn}\")\n",
    "    print(f\"Seed: {seed}\")\n",
    "    \n",
    "    hyper_params = [\n",
    "        {\"lr\": 0.01, \"weight_decay\": 0.0, \"momentum\": 0.0},\n",
    "        {\"lr\": 0.01, \"weight_decay\": 0.01, \"momentum\": 0.0},\n",
    "        {\"lr\": 0.01, \"weight_decay\": 0.9, \"momentum\": 0.0},\n",
    "        {\"lr\": 0.01, \"weight_decay\": 0.0, \"momentum\": 0.01},\n",
    "        {\"lr\": 0.01, \"weight_decay\": 0.0, \"momentum\": 0.9},\n",
    "        {\"lr\": 0.01, \"weight_decay\": 0.01, \"momentum\": 0.9},\n",
    "        {\"lr\": 0.01, \"weight_decay\": 0.9, \"momentum\": 0.01},\n",
    "    ]\n",
    "\n",
    "    models = []\n",
    "    accuracies = []\n",
    "\n",
    "    # Train both models with the different hyperparameters\n",
    "    for hparam in hyper_params:\n",
    "        print(\"\\n\", \"=\"*50)\n",
    "        print(\"\\tCurrent parameters: \")\n",
    "        [print(f\"{key}:{value}\") for key, value in hparam.items()]\n",
    "\n",
    "        print(\"\\n\", \"-\"*6, \"Using Pytorch SGD\", \"-\"*6)\n",
    "        torch.manual_seed(SEED)\n",
    "        model_auto = MyMLP()\n",
    "        model_auto.to(device=DEVICE)\n",
    "        optimizer = optim.SGD(model_auto.parameters(), **hparam)\n",
    "\n",
    "        train(n_epochs, optimizer, model_auto, loss_fn, train_loader, val_loader)\n",
    "        train_acc_auto = evaluate(model_auto, train_loader)\n",
    "        val_acc_auto = evaluate(model_auto, val_loader)\n",
    "        models.append(model_auto)\n",
    "        accuracies.append(val_acc_auto)\n",
    "        \n",
    "        print(\"\\n\", \"-\"*3, \"Accuracies\", \"-\"*3)\n",
    "        print(f\"Training accuracy: {round(train_acc_auto, 2)}\")\n",
    "        print(f\"Validation accuracy: {round(val_acc_auto, 2)}\")\n",
    "    return models, accuracies, hyper_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5396495f-d70c-43f9-a96d-602b4d488ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse Images\n",
    "training_set, _, _ = load_CIFAR2()\n",
    "\n",
    "display_images(training_set, save=True)\n",
    "\n",
    "print(\"Class distribution: \")\n",
    "counter = Counter([label for _, label in training_set])\n",
    "for label, count in counter.items():\n",
    "    print(f\"Label: {label} -> {count} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3c9bb2-1120-464f-91b6-ddaed08a14ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add normalization from training data\n",
    "tensor_train, _, _ = load_CIFAR2(preprocessor=transforms.ToTensor())\n",
    "imgs = torch.stack([img for img, _ in tensor_train])\n",
    "\n",
    "normalizer = transforms.Normalize(\n",
    "    imgs.mean(dim=(0,2,3)),\n",
    "    imgs.std(dim=(0,2,3))\n",
    ")\n",
    "\n",
    "preprocessor = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalizer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6564caf-1d37-4665-8d2e-e6f828f55ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "batch_size = 256\n",
    "\n",
    "# Load data with preprocessor\n",
    "cifar_train, cifar_val, cifar_test = load_CIFAR2(preprocessor=preprocessor)\n",
    "train_loader = DataLoader(cifar_train, shuffle=False, batch_size=batch_size)\n",
    "val_loader = DataLoader(cifar_val, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09897012-778c-4a0e-890f-e2ae26b35bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare both training functions and check for equal output (5 decimal precision)\n",
    "compare_training_functions(train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99785f79-5cbf-4aba-b805-bb229982e088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with different hyperparameters\n",
    "models, accuracies, hyper_params = train_instances(n_epochs, batch_size, train_loader=train_loader, val_loader=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7aa42d1-e1c9-4344-bf5c-d81dffe816b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the model with highest accuracy\n",
    "highest_acc = max(accuracies)\n",
    "selected_idx = accuracies.index(highest_acc)\n",
    "selected_model = models[selected_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712a0d31-b8fc-4a89-8d79-fc3c9f535df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test performance of chosen model on unseen data\n",
    "test_loader = DataLoader(cifar_test, shuffle=False, batch_size=batch_size)\n",
    "acc, cm = evaluate(selected_model, test_loader, calc_confusion_matrix=True)\n",
    "print(f\"Used hyperparameters: {hyper_params[selected_idx]}\")\n",
    "print(f\"Test Accuracy of selected model: {acc:.2f}\")\n",
    "\n",
    "# Visualize the confusion matrix. Positive = Airplane = 1, Negative = Bird = 0\n",
    "cmplt = ConfusionMatrixDisplay(cm, display_labels=[\"Bird\", \"Airplane\"])\n",
    "cmplt.plot()\n",
    "cmplt.ax_.set_title(\"Confusion matrix for predictions on the test set\")\n",
    "plt.savefig(\"imgs/confusion_matrix_test.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efedbf1a-43be-4905-a263-4ebd93ba8277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_wrong_predictions(model, loader, wrong=True, label=None, preprocessor=normalizer, save=False):\n",
    "    \"\"\"\n",
    "    Display some examples of wrongly classified images\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    kept_imgs, kept_labels, kept_preds = [],[],[]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "            imgs = imgs.to(device=DEVICE)\n",
    "            labels = labels.to(device=DEVICE)\n",
    "            outputs = model(imgs)\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            wrong_preds = torch.eq(labels, predicted)\n",
    "\n",
    "            kept_imgs+=[img.permute(1,2,0) for img in imgs[~wrong_preds]]\n",
    "            kept_labels+=labels[~wrong_preds].tolist()\n",
    "            kept_preds+=predicted[~wrong_preds].tolist()\n",
    "\n",
    "    kept_imgs = iter(kept_imgs)\n",
    "    kept_labels = iter(kept_labels)\n",
    "    kept_preds = iter(kept_preds)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=8, ncols=2, constrained_layout=True, figsize=(4,10))\n",
    "    fig.suptitle(\"Wrong predictions\\nTrue label: Plane(0)  True label: Bird(1)\\nPredicted: Bird(1)  Predicted: Plane(0)\")\n",
    "    for i, row in enumerate(axes):\n",
    "        for j, ax in enumerate(row):\n",
    "            img, pred = next(kept_imgs), next(kept_preds)\n",
    "            while label != j:\n",
    "                img, label = next(kept_imgs), next(kept_preds)\n",
    "                img = img.to(device='cpu')\n",
    "            ax.imshow(img, interpolation=\"nearest\", aspect=\"auto\")\n",
    "            ax.axis('off')\n",
    "\n",
    "    if save:\n",
    "        plt.savefig(\"imgs/wrong_predictions.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21133d81-fddf-4857-b6bc-d614b88a88f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display wrong predictions\n",
    "find_wrong_predictions(selected_model, test_loader, save=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
